{"cells":[{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":1274,"status":"ok","timestamp":1721232923197,"user":{"displayName":"Younghoon Kim","userId":"02502586489806404813"},"user_tz":-540},"id":"bsIXEH5vPeUB"},"outputs":[],"source":["import gymnasium as gym\n","env = gym.make('gym_examples:gym_examples/Reversi-v0', render_mode='text')"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/anaconda3/envs/pytorch_SKT/lib/python3.9/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment gym_examples/Reversi-v0 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"]}],"source":["import gymnasium as gym\n","from gymnasium.envs.registration import register\n","\n","register(\n","    id=\"gym_examples/Reversi-v0\",\n","    entry_point=\"gym_examples.envs:ReversiEnv\"\n",")\n","\n","env = gym.make('gym_examples/Reversi-v0', render_mode='text')"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1721232925344,"user":{"displayName":"Younghoon Kim","userId":"02502586489806404813"},"user_tz":-540},"id":"uYCQ5y0fP0mO","outputId":"aaedb231-e57b-4fbb-acfe-a2c55058fb1a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/anaconda3/envs/pytorch_SKT/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be uint8, actual type: int16\u001b[0m\n","  logger.warn(\n","/opt/anaconda3/envs/pytorch_SKT/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n","  logger.warn(f\"{pre} is not within the observation space.\")\n"]}],"source":["obs, info = env.reset() "]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":329,"status":"ok","timestamp":1721232928315,"user":{"displayName":"Younghoon Kim","userId":"02502586489806404813"},"user_tz":-540},"id":"kLJMo4TSQrIy","outputId":"0abb8bc3-a04d-41a7-c16f-d76ca88e56de"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current state of the board:\n","    0 1 2 3 4 5 6 7\n","-------------------\n","0 | . . . . . . . .\n","1 | . . . . . . . .\n","2 | . . . . . . . .\n","3 | . . . 1 2 . . .\n","4 | . . . 2 1 . . .\n","5 | . . . . . . . .\n","6 | . . . . . . . .\n","7 | . . . . . . . .\n","Gym player: 2, Agent player: 1\n","<class 'str'>\n"]}],"source":["env.render()"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1721232931329,"user":{"displayName":"Younghoon Kim","userId":"02502586489806404813"},"user_tz":-540},"id":"fpY3W6eOeQrb","outputId":"0cdd9cab-e751-43fd-e2fd-39a1d61e6cd3"},"outputs":[{"data":{"text/plain":["array([[0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 1, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 1, 0, 0],\n","       [0, 0, 1, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 1, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["info['action_mask']"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":323,"status":"ok","timestamp":1721232934960,"user":{"displayName":"Younghoon Kim","userId":"02502586489806404813"},"user_tz":-540},"id":"LwsoJLX0nTMC","outputId":"171c7b7a-50e2-4d42-eb92-a9ab5360f0d9"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/anaconda3/envs/pytorch_SKT/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be uint8, actual type: int16\u001b[0m\n","  logger.warn(\n","/opt/anaconda3/envs/pytorch_SKT/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n","  logger.warn(f\"{pre} is not within the observation space.\")\n"]}],"source":["obs, reward, done, _, info = env.step((2,4))"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":390,"status":"ok","timestamp":1721232938703,"user":{"displayName":"Younghoon Kim","userId":"02502586489806404813"},"user_tz":-540},"id":"sZegK_bTnhr0","outputId":"89c4420d-1d17-464b-8a2c-a9c3202f8cfe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current state of the board:\n","    0 1 2 3 4 5 6 7\n","-------------------\n","0 | . . . . . . . .\n","1 | . . . . . . . .\n","2 | . . . . 1 2 . .\n","3 | . . . 1 2 . . .\n","4 | . . . 2 1 . . .\n","5 | . . . . . . . .\n","6 | . . . . . . . .\n","7 | . . . . . . . .\n","Gym player: 2, Agent player: 1\n","<class 'str'>\n"]}],"source":["env.render()"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":386,"status":"ok","timestamp":1721232941460,"user":{"displayName":"Younghoon Kim","userId":"02502586489806404813"},"user_tz":-540},"id":"Dhmc2hPgeQrc","outputId":"fefb67a5-91fa-4dd0-b688-da5649fe5a6c"},"outputs":[{"data":{"text/plain":["array([[0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 1, 0],\n","       [0, 0, 0, 0, 0, 1, 0, 0],\n","       [0, 0, 1, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 1, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["info['action_mask']"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1721232944487,"user":{"displayName":"Younghoon Kim","userId":"02502586489806404813"},"user_tz":-540},"id":"rnSgMbtHnppw"},"outputs":[{"ename":"AssertionError","evalue":"Invalid action (2, 2). Possible moves are [(2, 6), (3, 5), (4, 2), (5, 3)]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m obs, reward, done, _,info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/anaconda3/envs/pytorch_SKT/lib/python3.9/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/anaconda3/envs/pytorch_SKT/lib/python3.9/site-packages/gymnasium/wrappers/env_checker.py:51\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/SKT FLY AI/Reinfocement/gym_examples/envs/reversi_random_template.py:283\u001b[0m, in \u001b[0;36mReversiEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    281\u001b[0m possible_moves \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpossible_moves(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAGENT_PLAYER, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m possible_moves, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo possible moves for the agent\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 283\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m possible_moves, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid action \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Possible moves are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpossible_moves\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# 에이전트 행동 전 상태 저장\u001b[39;00m\n\u001b[1;32m    286\u001b[0m state_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mcopy()\n","\u001b[0;31mAssertionError\u001b[0m: Invalid action (2, 2). Possible moves are [(2, 6), (3, 5), (4, 2), (5, 3)]"]}],"source":["obs, reward, done, _,info = env.step((2, 2))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278,"status":"ok","timestamp":1715059708358,"user":{"displayName":"Younghoon Kim","userId":"02502586489806404813"},"user_tz":-540},"id":"Ah-LJysvn0sq","outputId":"b915d003-ad5a-40c2-cb24-ff9a14b1c847"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current state of the board:\n","    0 1 2 3 4 5 6 7\n","-------------------\n","0 | . . . . . . . .\n","1 | . . . . . . . .\n","2 | . . 1 1 1 2 . .\n","3 | . . . 1 2 . . .\n","4 | . . . 2 1 . . .\n","5 | . . . . . . . .\n","6 | . . . . . . . .\n","7 | . . . . . . . .\n","<class 'str'>\n"]}],"source":["env.render()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":425,"status":"ok","timestamp":1721232949037,"user":{"displayName":"Younghoon Kim","userId":"02502586489806404813"},"user_tz":-540},"id":"cz6bTlp3eQrd","outputId":"e2a41aed-3e66-4859-c942-2cea9ba10c58"},"outputs":[{"data":{"text/plain":["array([[0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 1, 0],\n","       [0, 0, 0, 0, 0, 1, 0, 0],\n","       [0, 0, 1, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 1, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["info['action_mask']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":364,"status":"ok","timestamp":1721232953337,"user":{"displayName":"Younghoon Kim","userId":"02502586489806404813"},"user_tz":-540},"id":"7Q2T3wb5n4tL","outputId":"781663e2-79bc-4178-c914-fb8c9fbfc790"},"outputs":[{"ename":"AssertionError","evalue":"Invalid action (0, 2). Possible moves are [(2, 6), (3, 5), (4, 2), (5, 3)]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m obs, reward, done,_, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m env\u001b[38;5;241m.\u001b[39mrender()\n","File \u001b[0;32m/opt/anaconda3/envs/pytorch_SKT/lib/python3.9/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/anaconda3/envs/pytorch_SKT/lib/python3.9/site-packages/gymnasium/wrappers/env_checker.py:51\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/SKT FLY AI/Reinfocement/gym_examples/envs/reversi_random_template.py:283\u001b[0m, in \u001b[0;36mReversiEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    281\u001b[0m possible_moves \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpossible_moves(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAGENT_PLAYER, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m possible_moves, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo possible moves for the agent\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 283\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m possible_moves, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid action \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Possible moves are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpossible_moves\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# 에이전트 행동 전 상태 저장\u001b[39;00m\n\u001b[1;32m    286\u001b[0m state_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mcopy()\n","\u001b[0;31mAssertionError\u001b[0m: Invalid action (0, 2). Possible moves are [(2, 6), (3, 5), (4, 2), (5, 3)]"]}],"source":["obs, reward, done,_, info = env.step((0, 2))\n","env.render()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":384,"status":"ok","timestamp":1721232962350,"user":{"displayName":"Younghoon Kim","userId":"02502586489806404813"},"user_tz":-540},"id":"ARJXRh1zn-G0","outputId":"b2695dfd-2e95-4d01-c07f-c4a4d82debb4"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as T"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["gamma = 0.99\n","epsilon = 1.0\n","epsilon_max = 1.0\n","epsilon_min = 0.1\n","epsilon_interval = epsilon_max - epsilon_min\n","batch_size = 16\n","max_steps_per_episode = 60\n","max_episodes = 10000"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["Box(0, 255, (8, 8, 1), uint8)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["env.observation_space"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_actions = 64"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class QModel(nn.Module):\n","  def __init__(self, num_actions):\n","    super(QModel, self).__init__()\n","    self.dropout = nn.Dropout(p=0.3)\n","    self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding='same')\n","    self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding='same')\n","    self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1)\n","    self.flatten = nn.Flatten()\n","    self.fc1 = nn.Linear(1152, 512)\n","    self.fc2 = nn.Linear(512, num_actions)\n","\n","  def forward(self, x):\n","    x = nn.functional.relu(self.conv1(x))\n","    x = nn.functional.relu(self.conv2(x))\n","    x = self.dropout(x)\n","    x = nn.functional.relu(self.conv3(x))\n","    x = self.flatten(x)\n","    x = nn.functional.relu(self.fc1(x))\n","    x = self.dropout(x)\n","    return self.fc2(x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = QModel(num_actions)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_target = QModel(num_actions)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss_function = nn.SmoothL1Loss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.00025)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["action_history = []\n","action_mask_history = []\n","state_history = []\n","state_next_history = []\n","rewards_history = []\n","done_history = []"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["episode_reward_history = []\n","running_reward = 0.\n","episode_count = 0\n","frame_count = 0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["epsilon_random_frames = 50000\n","# Number of frames for exploration\n","epsilon_greedy_frames = 200000.0\n","# Maximum replay length\n","# Note: The Deepmind paper suggests 1000000 however this causes memory issues\n","max_memory_length = 500000\n","# Train the model after 4 actions\n","update_after_actions = 4\n","# How often to update the target network\n","update_target_network = 10000"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess_state(obs):\n","  st = torch.from_numpy(obs).squeeze()\n","  st = st.to(torch.int64)\n","  st = torch.nn.functional.one_hot(st, num_classes=3)\n","  st = st.permute(2, 0, 1)\n","  return st.to(torch.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["board, info = env.reset()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([3, 8, 8])"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["st = preprocess_state(board)\n","st.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_greedy_epsilon(model, state, mask):\n","  global epsilon\n","\n","  #if frame_count < epsilon_random_frames or np.random.rand(1)[0] < epsilon:\n","  if np.random.rand(1)[0] < epsilon:\n","    action = np.random.choice([ i for i in range(num_actions) if mask[i] == 1 ])\n","  else:\n","    with torch.no_grad():\n","      # add a batch axis\n","      state_tensor = state.unsqueeze(0)\n","      # compute the q-values\n","      q_values = model(state_tensor)\n","      # select the q-values of valid actions\n","      action = torch.argmax(\n","        q_values.squeeze() + torch.from_numpy(mask) * 100., dim=0)\n","\n","  epsilon -= epsilon_interval / epsilon_greedy_frames\n","  epsilon = max(epsilon, epsilon_min)\n","  return action"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_greedy_action(model, state, mask):\n","  global epsilon\n","  with torch.no_grad():\n","    state_tensor = state.unsqueeze(0) # batch dimension\n","    q_values = model(state_tensor)\n","    action = torch.argmax(\n","      q_values.squeeze() + torch.from_numpy(mask) * 100.,dim=0)\n","  return action"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def sample_batch(_batch_size):\n","  indices = np.random.choice(range(len(done_history)), size=_batch_size, replace=False)\n","  state_sample = np.array([state_history[i].squeeze(0).numpy() for i in indices])\n","  state_next_sample = np.array([state_next_history[i].squeeze(0).numpy() for i in indices])\n","  rewards_sample = np.array([rewards_history[i] for i in indices], dtype=np.float32)\n","  action_sample = np.array([action_history[i] for i in indices])\n","\n","  # action mask is the mask for the valid actions at the '''next''' state\n","  action_mask_sample = np.array([action_mask_history[i] for i in indices])\n","  done_sample = np.array([float(done_history[i]) for i in indices])\n","  return state_sample, state_next_sample, rewards_sample, action_sample, action_mask_sample, done_sample"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def update_network():\n","  state_sample, state_next_sample, rewards_sample, action_sample, action_mask_sample, done_sample = \\\n","    sample_batch(batch_size)\n","\n","  state_sample = torch.tensor(state_sample, dtype=torch.float32)\n","  state_next_sample = torch.tensor(state_next_sample, dtype=torch.float32)\n","  action_sample = torch.tensor(action_sample, dtype=torch.int64)\n","  action_mask_sample = torch.tensor(action_mask_sample, dtype=torch.int64)\n","  rewards_sample = torch.tensor(rewards_sample, dtype=torch.float32)\n","  done_sample = torch.tensor(done_sample, dtype=torch.float32)\n","\n","  with torch.no_grad():\n","    future_rewards = model_target(state_next_sample)\n","    max_q_values = torch.max (\n","        future_rewards + action_mask_sample * 100.,\n","    dim=1).values.detach() - 100.\n","    target_q_values = rewards_sample + gamma * max_q_values * (1. - done_sample)\n","\n","  q_values = model(state_sample)\n","  q_values_action = q_values.gather(dim=1, index=action_sample.unsqueeze(1)).squeeze(1)\n","  loss = loss_function(q_values_action, target_q_values)\n","  optimizer.zero_grad()\n","  loss.backward()\n","  optimizer.step()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["10 303 32.9\n","20 607 -8.325\n","30 881 10.383333333333333\n","40 1184 -11.1875\n","50 1485 -9.09\n","60 1786 -8.566666666666666\n","70 2089 -5.928571428571429\n","80 2366 -1.15\n","90 2672 -4.072222222222222\n","100 2971 -1.115\n","110 3273 -4.645\n","120 3577 -5.925\n","130 3879 -19.465\n","140 4182 -16.0\n","150 4483 -22.35\n","160 4783 -27.565\n","170 5085 -31.605\n","180 5386 -35.92\n","190 5688 -32.76\n","200 5990 -33.035\n","210 6294 -32.435\n","220 6595 -38.365\n","230 6901 -28.82\n","240 7204 -20.465\n","250 7505 -18.775\n","260 7807 -18.2\n","270 8107 -16.985\n","280 8409 -14.755\n","290 8710 -17.775\n","300 9012 -25.25\n","310 9315 -21.165\n","320 9615 -8.195\n","330 9913 -8.39\n","340 10214 -15.505\n","350 10515 -4.445\n","360 10817 -7.95\n","370 11112 -16.085\n","380 11416 -9.66\n","390 11716 -5.94\n","400 12018 -1.365\n","410 12320 -5.14\n","420 12622 -11.84\n","430 12920 -10.935\n","440 13220 -5.55\n","450 13522 -11.32\n","460 13822 -6.075\n","470 14124 4.57\n","480 14427 -2.19\n","490 14728 -9.785\n","500 15029 -19.075\n","510 15332 -22.125\n","520 15632 -17.89\n","530 15934 -19.32\n","540 16237 -21.3\n","550 16541 -21.305\n","560 16844 -10.125\n","570 17143 -16.655\n","580 17439 -16.27\n","590 17740 -10.225\n","600 18040 -1.26\n","610 18342 0.71\n","620 18639 -0.41\n","630 18942 2.435\n","640 19246 9.475\n","650 19547 5.245\n","660 19847 -7.825\n","670 20148 -1.365\n","680 20448 -4.625\n","690 20750 -8.795\n","700 21050 -10.035\n","710 21352 -10.26\n","720 21656 -3.935\n","730 21959 -6.985\n","740 22259 -17.15\n","750 22561 -21.255\n","760 22861 -21.5\n","770 23163 -23.745\n","780 23463 -25.28\n","790 23765 -18.685\n","800 24066 -22.705\n","810 24368 -18.605\n","820 24670 -16.195\n","830 24971 -15.55\n","840 25275 -15.065\n","850 25578 -7.59\n","860 25878 -4.33\n","870 26179 -0.54\n","880 26481 3.285\n","890 26784 0.71\n","900 27086 7.42\n","910 27389 10.86\n","920 27695 2.725\n","930 27997 6.365\n","940 28301 12.675\n","950 28603 6.9\n","960 28906 7.885\n","970 29206 -1.97\n","980 29508 -2.24\n","990 29809 -10.24\n","1000 30111 -14.265\n","1010 30415 -20.855\n","1020 30718 -16.61\n","1030 31020 -18.18\n","1040 31323 -21.545\n","1050 31624 -16.315\n","1060 31926 -15.635\n","1070 32228 -6.41\n","1080 32529 -2.92\n","1090 32831 12.99\n","1100 33132 20.88\n","1110 33434 27.395\n","1120 33736 27.33\n","1130 34040 29.045\n","1140 34342 28.195\n","1150 34645 34.62\n","1160 34948 37.39\n","1170 35243 40.7\n","1180 35525 35.635\n","1190 35826 24.43\n","1200 36127 21.075\n","1210 36430 13.83\n","1220 36732 11.445\n","1230 37035 13.15\n","1240 37336 16.98\n","1250 37639 9.8\n","1260 37941 5.87\n","1270 38243 3.095\n","1280 38547 9.545\n","1290 38849 24.125\n","1300 39153 34.785\n","1310 39458 37.91\n","1320 39759 36.055\n","1330 40059 27.205\n","1340 40363 29.93\n","1350 40666 34.175\n","1360 40967 36.985\n","1370 41268 35.21\n","1380 41567 29.555\n","1390 41868 15.86\n","1400 42169 3.5\n","1410 42470 0.505\n","1420 42773 7.655\n","1430 43075 16.685\n","1440 43376 15.375\n","1450 43677 12.6\n","1460 43981 17.615\n","1470 44283 18.1\n","1480 44565 26.495\n","1490 44868 31.74\n","1500 45167 33.05\n","1510 45469 36.66\n","1520 45770 35.405\n","1530 46073 32.885\n","1540 46376 27.37\n","1550 46683 37.915\n","1560 46986 35.89\n","1570 47290 37.275\n","1580 47591 33.49\n","1590 47895 38.0\n","1600 48196 40.07\n","1610 48495 31.765\n","1620 48798 32.23\n","1630 49099 28.885\n","1640 49400 35.275\n","1650 49699 23.345\n","1660 50003 26.77\n","1670 50303 23.505\n","1680 50604 20.7\n","1690 50908 21.965\n","1700 51210 19.72\n","1710 51510 21.47\n","1720 51811 27.155\n","1730 52110 26.905\n","1740 52411 21.915\n","1750 52714 27.205\n","1760 53016 25.845\n","1770 53318 24.69\n","1780 53621 19.77\n","1790 53926 17.18\n","1800 54228 22.39\n","1810 54529 33.365\n","1820 54831 21.415\n","1830 55132 14.195\n","1840 55436 11.1\n","1850 55739 13.235\n","1860 56037 13.29\n","1870 56334 18.725\n","1880 56638 24.91\n","1890 56940 22.89\n","1900 57241 15.265\n","1910 57543 16.185\n","1920 57833 16.075\n","1930 58132 24.86\n","1940 58431 30.085\n","1950 58709 26.48\n","1960 59013 25.855\n","1970 59316 29.705\n","1980 59619 34.17\n","1990 59921 35.675\n","2000 60222 38.855\n","2010 60524 41.335\n","2020 60825 46.135\n","2030 61125 43.855\n","2040 61425 44.985\n","2050 61726 41.225\n","2060 62028 35.67\n","2070 62331 36.945\n","2080 62630 32.72\n","2090 62930 30.08\n","2100 63231 36.845\n","2110 63533 32.145\n","2120 63833 34.365\n","2130 64137 37.54\n","2140 64440 41.42\n","2150 64744 47.895\n","2160 65047 48.01\n","2170 65350 49.175\n","2180 65651 49.125\n","2190 65952 45.745\n","2200 66254 37.235\n","2210 66558 35.63\n","2220 66843 29.17\n","2230 67146 31.18\n","2240 67446 14.71\n","2250 67748 18.795\n","2260 68046 24.945\n","2270 68349 26.755\n","2280 68651 23.435\n","2290 68954 29.93\n","2300 69254 23.905\n","2310 69557 21.595\n","2320 69840 25.2\n","2330 70141 22.195\n","2340 70440 28.005\n","2350 70741 22.02\n","2360 71046 16.84\n","2370 71347 4.68\n","2380 71647 9.115\n","2390 71949 8.185\n","2400 72252 20.295\n","2410 72553 20.11\n","2420 72853 22.065\n","2430 73156 26.705\n","2440 73460 32.935\n","2450 73754 35.635\n","2460 74057 30.255\n","2470 74348 33.35\n","2480 74653 35.95\n","2490 74956 31.015\n","2500 75258 25.765\n","2510 75558 24.565\n","2520 75862 24.805\n","2530 76166 22.445\n","2540 76467 19.33\n","2550 76769 19.09\n","2560 77068 24.075\n","2570 77346 33.635\n","2580 77649 32.635\n","2590 77927 41.4\n","2600 78228 48.31\n","2610 78529 49.365\n","2620 78831 46.67\n","2630 79130 49.525\n","2640 79430 48.615\n","2650 79728 40.625\n","2660 80033 46.21\n","2670 80335 35.015\n","2680 80637 32.44\n","2690 80940 28.115\n","2700 81243 22.355\n","2710 81544 22.365\n","2720 81845 31.075\n","2730 82138 25.36\n","2740 82440 34.43\n","2750 82743 37.88\n","2760 83042 31.39\n","2770 83343 38.31\n","2780 83643 38.34\n","2790 83942 35.76\n","2800 84245 38.515\n","2810 84546 42.455\n","2820 84846 31.945\n","2830 85147 35.21\n","2840 85449 32.745\n","2850 85750 31.705\n","2860 86055 32.84\n","2870 86329 32.24\n","2880 86607 35.27\n","2890 86911 43.745\n","2900 87214 40.495\n","2910 87515 38.435\n","2920 87821 40.655\n","2930 88124 39.53\n","2940 88427 41.99\n","2950 88729 45.465\n","2960 89032 47.2\n","2970 89328 44.47\n","2980 89632 38.06\n","2990 89933 32.69\n","3000 90235 37.74\n","3010 90539 42.855\n","3020 90838 48.555\n","3030 91143 54.905\n","3040 91442 43.43\n","3050 91744 36.87\n","3060 92043 41.25\n","3070 92349 44.455\n","3080 92651 53.135\n","3090 92955 52.085\n","3100 93243 45.43\n","3110 93545 46.47\n","3120 93845 43.0\n","3130 94147 44.425\n","3140 94428 51.425\n","3150 94728 59.61\n","3160 95028 49.09\n","3170 95329 45.735\n","3180 95629 41.665\n","3190 95934 44.815\n","3200 96236 52.46\n","3210 96540 42.56\n","3220 96842 45.475\n","3230 97146 41.885\n","3240 97450 43.1\n","3250 97754 36.69\n","3260 98054 38.925\n","3270 98355 39.165\n","3280 98656 43.37\n","3290 98956 39.37\n","3300 99259 39.28\n","3310 99559 35.04\n","3320 99858 35.93\n","3330 100161 33.725\n","3340 100463 34.05\n","3350 100767 44.885\n","3360 101071 49.87\n","3370 101373 51.115\n","3380 101669 50.205\n","3390 101969 46.365\n","3400 102272 41.065\n","3410 102572 42.135\n","3420 102874 43.735\n","3430 103175 34.41\n","3440 103479 35.185\n","3450 103782 32.42\n","3460 104059 25.9\n","3470 104363 26.86\n","3480 104664 23.99\n","3490 104964 25.775\n","3500 105267 36.19\n","3510 105570 42.885\n","3520 105868 36.125\n","3530 106170 48.085\n","3540 106470 49.265\n","3550 106774 50.23\n","3560 107076 59.115\n","3570 107376 53.985\n","3580 107678 57.59\n","3590 107980 65.18\n","3600 108285 55.12\n","3610 108587 58.095\n","3620 108887 62.155\n","3630 109191 54.525\n","3640 109495 52.925\n","3650 109799 49.335\n","3660 110099 49.565\n","3670 110405 50.69\n","3680 110704 45.72\n","3690 111008 43.155\n","3700 111310 47.73\n","3710 111604 42.075\n","3720 111905 39.53\n","3730 112206 47.135\n","3740 112505 45.22\n","3750 112807 47.605\n","3760 113107 46.92\n","3770 113407 45.005\n","3780 113706 46.185\n","3790 114001 45.175\n","3800 114301 46.76\n","3810 114604 50.67\n","3820 114906 52.395\n","3830 115209 50.74\n","3840 115502 51.615\n","3850 115805 50.27\n","3860 116106 51.32\n","3870 116405 57.895\n","3880 116707 57.085\n","3890 117007 56.95\n","3900 117308 57.305\n","3910 117609 61.46\n","3920 117910 58.155\n","3930 118215 59.065\n","3940 118514 59.53\n","3950 118814 62.7\n","3960 119114 59.3\n","3970 119418 58.54\n","3980 119689 61.455\n","3990 119993 66.485\n","4000 120295 59.58\n","4010 120597 57.85\n","4020 120898 65.37\n","4030 121199 62.59\n","4040 121500 63.06\n","4050 121800 61.88\n","4060 122103 62.655\n","4070 122406 68.325\n","4080 122707 74.325\n","4090 123009 67.065\n","4100 123285 72.9\n","4110 123587 67.16\n","4120 123877 62.765\n","4130 124178 65.415\n","4140 124478 59.54\n","4150 124778 47.115\n","4160 125080 48.89\n","4170 125384 39.525\n","4180 125689 36.955\n","4190 125997 46.24\n","4200 126295 35.86\n","4210 126595 36.82\n","4220 126897 33.86\n","4230 127198 28.825\n","4240 127501 31.125\n","4250 127801 38.835\n","4260 128104 38.56\n","4270 128407 41.53\n","4280 128708 41.555\n","4290 129010 37.105\n","4300 129311 43.075\n","4310 129612 38.73\n","4320 129914 39.55\n","4330 130211 43.14\n","4340 130510 42.22\n","4350 130812 45.715\n","4360 131116 42.035\n","4370 131418 44.565\n","4380 131722 42.085\n","4390 132024 38.825\n","4400 132325 34.085\n","4410 132628 38.625\n","4420 132928 26.92\n","4430 133228 29.245\n","4440 133528 37.085\n","4450 133831 34.265\n","4460 134133 38.035\n","4470 134428 34.77\n","4480 134729 24.285\n","4490 135032 20.885\n","4500 135332 32.135\n","4510 135633 33.435\n","4520 135930 49.75\n","4530 136229 43.865\n","4540 136530 40.24\n","4550 136832 38.765\n","4560 137135 39.975\n","4570 137435 40.775\n","4580 137737 50.54\n","4590 138031 60.79\n","4600 138333 57.78\n","4610 138633 59.42\n","4620 138931 56.08\n","4630 139235 63.625\n","4640 139536 59.84\n","4650 139839 64.11\n","4660 140136 66.66\n","4670 140438 64.14\n","4680 140739 60.05\n","4690 141040 52.365\n","4700 141342 51.225\n","4710 141643 55.14\n","4720 141946 59.15\n","4730 142247 58.465\n","4740 142547 61.76\n","4750 142844 60.23\n","4760 143144 51.625\n","4770 143439 54.415\n","4780 143739 62.715\n","4790 144044 66.69\n","4800 144345 67.185\n","4810 144647 60.21\n","4820 144947 57.82\n","4830 145249 49.985\n","4840 145551 49.02\n","4850 145855 54.475\n","4860 146157 53.94\n","4870 146447 51.985\n","4880 146747 49.24\n","4890 147047 46.84\n","4900 147322 45.585\n","4910 147617 45.25\n","4920 147920 48.195\n","4930 148221 54.945\n","4940 148523 56.065\n","4950 148829 53.85\n","4960 149131 66.385\n","4970 149432 68.805\n","4980 149734 63.45\n","4990 150036 64.775\n","5000 150338 72.82\n","5010 150642 77.59\n","5020 150943 73.52\n","5030 151244 74.19\n","5040 151547 67.915\n","5050 151849 67.615\n","5060 152150 58.98\n","5070 152448 56.735\n","5080 152750 60.705\n","5090 153053 63.985\n","5100 153357 55.815\n","5110 153658 54.405\n","5120 153965 56.19\n","5130 154270 56.685\n","5140 154575 62.76\n","5150 154864 66.01\n","5160 155166 68.535\n","5170 155467 63.555\n","5180 155770 62.96\n","5190 156072 57.125\n","5200 156376 57.485\n","5210 156678 60.06\n","5220 156983 58.475\n","5230 157284 53.19\n","5240 157582 48.29\n","5250 157881 48.825\n","5260 158182 48.005\n","5270 158483 51.955\n","5280 158786 49.66\n","5290 159086 51.52\n","5300 159388 48.085\n","5310 159692 41.065\n","5320 159993 38.33\n","5330 160298 40.465\n","5340 160598 44.865\n","5350 160899 39.36\n","5360 161202 40.88\n","5370 161502 42.435\n","5380 161806 41.37\n","5390 162107 43.185\n","5400 162408 40.925\n","5410 162713 44.0\n","5420 163003 45.595\n","5430 163303 47.825\n","5440 163605 50.215\n","5450 163905 43.895\n","5460 164208 45.825\n","5470 164509 50.08\n","5480 164811 49.405\n","5490 165114 46.265\n","5500 165419 56.755\n","5510 165717 50.945\n","5520 166018 49.315\n","5530 166323 53.925\n","5540 166624 55.545\n","5550 166930 68.17\n","5560 167233 66.295\n","5570 167533 66.07\n","5580 167835 68.435\n","5590 168140 75.435\n","5600 168443 69.9\n","5610 168744 83.295\n","5620 169048 90.335\n","5630 169353 79.335\n","5640 169656 66.33\n","5650 169959 60.245\n","5660 170262 62.435\n","5670 170564 63.62\n","5680 170864 61.57\n","5690 171168 61.345\n","5700 171472 66.595\n","5710 171772 54.105\n","5720 172076 47.975\n","5730 172376 54.55\n","5740 172679 55.885\n","5750 172982 50.645\n","5760 173284 45.595\n","5770 173584 41.125\n","5780 173885 46.125\n","5790 174189 41.425\n","5800 174494 43.69\n","5810 174786 46.47\n","5820 175088 52.56\n","5830 175388 53.59\n","5840 175687 67.8\n","5850 175987 75.87\n","5860 176286 72.405\n","5870 176590 71.51\n","5880 176893 72.47\n","5890 177196 72.715\n","5900 177496 64.81\n","5910 177798 75.665\n","5920 178100 69.36\n","5930 178402 60.715\n","5940 178706 52.445\n","5950 179005 48.74\n","5960 179308 51.99\n","5970 179610 57.225\n","5980 179913 52.52\n","5990 180215 44.575\n","6000 180519 48.64\n","6010 180822 39.88\n","6020 181124 41.71\n","6030 181426 45.66\n","6040 181728 52.87\n","6050 182030 58.09\n","6060 182337 59.785\n","6070 182638 56.84\n","6080 182941 57.81\n","6090 183247 68.875\n","6100 183546 61.935\n","6110 183850 60.92\n","6120 184153 57.845\n","6130 184444 52.64\n","6140 184747 51.325\n","6150 185051 42.295\n","6160 185357 42.08\n","6170 185658 40.6\n","6180 185962 43.205\n","6190 186266 40.725\n","6200 186565 46.27\n","6210 186867 51.175\n","6220 187172 54.9\n","6230 187474 60.13\n","6240 187776 53.73\n","6250 188077 60.745\n","6260 188381 61.375\n","6270 188689 63.325\n","6280 188990 61.33\n","6290 189295 63.545\n","6300 189597 61.62\n","6310 189901 56.97\n","6320 190203 54.795\n","6330 190505 53.705\n","6340 190808 61.315\n","6350 191111 61.405\n","6360 191411 54.075\n","6370 191710 51.795\n","6380 192013 54.505\n","6390 192317 51.75\n","6400 192619 48.475\n","6410 192921 45.965\n","6420 193201 52.11\n","6430 193502 56.375\n","6440 193806 52.46\n","6450 194108 50.705\n","6460 194409 53.41\n","6470 194710 54.63\n","6480 195012 52.81\n","6490 195288 49.695\n","6500 195593 57.265\n","6510 195898 60.64\n","6520 196197 62.05\n","6530 196498 59.44\n","6540 196800 58.125\n","6550 197102 56.245\n","6560 197404 64.49\n","6570 197707 63.97\n","6580 198013 69.04\n","6590 198315 74.56\n","6600 198616 74.81\n","6610 198918 67.915\n","6620 199219 60.905\n","6630 199522 60.81\n","6640 199826 57.125\n","6650 200126 52.805\n","6660 200433 50.825\n","6670 200735 54.17\n","6680 201041 53.585\n","6690 201342 49.985\n","6700 201645 48.72\n","6710 201949 59.77\n","6720 202250 66.93\n","6730 202553 72.48\n","6740 202855 75.58\n","6750 203141 79.94\n","6760 203443 80.76\n","6770 203744 80.19\n","6780 204046 72.86\n","6790 204347 68.355\n","6800 204649 63.43\n","6810 204925 60.265\n","6820 205227 57.075\n","6830 205530 53.7\n","6840 205832 56.215\n","6850 206136 59.97\n","6860 206438 56.28\n","6870 206740 55.395\n","6880 207044 62.47\n","6890 207346 70.615\n","6900 207649 74.84\n","6910 207947 71.02\n","6920 208249 71.265\n","6930 208549 67.895\n","6940 208846 67.46\n","6950 209150 64.815\n","6960 209453 70.06\n","6970 209755 73.805\n","6980 210059 70.53\n","6990 210362 63.52\n","7000 210663 62.405\n","7010 210964 62.145\n","7020 211268 58.485\n","7030 211566 62.965\n","7040 211867 64.11\n","7050 212168 63.96\n","7060 212470 63.815\n","7070 212771 58.805\n","7080 213073 58.94\n","7090 213370 61.8\n","7100 213671 53.465\n","7110 213974 54.755\n","7120 214274 57.665\n","7130 214576 57.01\n","7140 214878 58.555\n","7150 215181 63.07\n","7160 215484 60.255\n","7170 215786 56.035\n","7180 216089 50.84\n","7190 216390 54.18\n","7200 216695 66.955\n","7210 216999 71.44\n","7220 217302 70.26\n","7230 217603 68.925\n","7240 217908 70.205\n","7250 218209 69.205\n","7260 218510 69.095\n","7270 218816 74.085\n","7280 219117 80.045\n","7290 219418 78.99\n","7300 219719 77.21\n","7310 220020 79.66\n","7320 220324 79.725\n","7330 220626 82.37\n","7340 220927 76.825\n","7350 221231 80.205\n","7360 221533 81.39\n","7370 221834 81.345\n","7380 222135 82.12\n","7390 222436 78.5\n","7400 222739 76.585\n","7410 223040 67.91\n","7420 223343 69.485\n","7430 223641 72.17\n","7440 223945 73.715\n","7450 224246 70.655\n","7460 224545 70.895\n","7470 224844 66.13\n","7480 225151 64.335\n","7490 225454 67.495\n","7500 225755 67.95\n","7510 226060 76.58\n","7520 226363 72.21\n","7530 226665 68.94\n","7540 226960 67.135\n","7550 227260 59.635\n","7560 227561 57.74\n","7570 227841 65.72\n","7580 228114 58.645\n","7590 228415 62.415\n","7600 228715 58.075\n","7610 229016 47.985\n","7620 229318 48.245\n","7630 229620 44.29\n","7640 229922 40.675\n","7650 230221 35.85\n","7660 230524 30.225\n","7670 230826 20.425\n","7680 231101 26.995\n","7690 231404 20.625\n","7700 231707 21.295\n","7710 232009 26.08\n","7720 232310 26.595\n","7730 232613 32.36\n","7740 232919 44.21\n","7750 233221 50.09\n","7760 233522 56.055\n","7770 233824 60.445\n","7780 234127 66.61\n","7790 234428 67.31\n","7800 234730 72.145\n","7810 235031 70.93\n","7820 235334 71.38\n","7830 235635 64.565\n","7840 235938 58.765\n","7850 236238 61.275\n","7860 236536 64.365\n","7870 236832 61.73\n","7880 237134 59.085\n","7890 237434 61.38\n","7900 237736 59.055\n","7910 238040 65.305\n","7920 238341 64.865\n","7930 238642 68.145\n","7940 238941 67.535\n","7950 239244 74.295\n","7960 239546 74.05\n","7970 239849 81.64\n","7980 240152 76.86\n","7990 240455 75.755\n","8000 240758 71.46\n","8010 241062 70.45\n","8020 241364 74.25\n","8030 241668 76.81\n","8040 241971 71.525\n","8050 242271 65.51\n","8060 242575 61.33\n","8070 242880 61.965\n","8080 243184 59.81\n","8090 243487 59.24\n","8100 243785 60.485\n","8110 244087 59.485\n","8120 244390 57.535\n","8130 244691 52.595\n","8140 244993 59.4\n","8150 245296 54.475\n","8160 245597 53.94\n","8170 245899 43.875\n","8180 246200 48.39\n","8190 246504 46.74\n","8200 246805 44.665\n","8210 247107 40.775\n","8220 247407 35.905\n","8230 247705 35.065\n","8240 248006 38.545\n","8250 248308 40.325\n","8260 248611 44.065\n","8270 248912 46.165\n","8280 249216 45.74\n","8290 249517 45.655\n","8300 249820 54.715\n","8310 250122 55.29\n","8320 250423 63.085\n","8330 250723 59.83\n","8340 251025 54.375\n","8350 251331 62.04\n","8360 251634 59.655\n","8370 251913 63.125\n","8380 252213 63.82\n","8390 252515 69.43\n","8400 252819 65.485\n","8410 253120 67.715\n","8420 253425 71.1\n","8430 253727 77.515\n","8440 254031 82.945\n","8450 254333 79.985\n","8460 254633 80.975\n","8470 254935 78.905\n","8480 255237 80.36\n","8490 255529 78.825\n","8500 255832 79.325\n","8510 256133 73.27\n","8520 256437 73.065\n","8530 256738 74.29\n","8540 257037 67.26\n","8550 257341 65.63\n","8560 257644 70.635\n","8570 257946 71.88\n","8580 258250 74.765\n","8590 258552 75.645\n","8600 258830 78.225\n","8610 259110 85.3\n","8620 259411 81.5\n","8630 259713 78.915\n","8640 260015 81.83\n","8650 260317 84.805\n","8660 260620 82.025\n","8670 260922 89.38\n","8680 261225 87.14\n","8690 261527 85.82\n","8700 261829 86.13\n","8710 262132 84.07\n","8720 262433 80.845\n","8730 262738 79.645\n","8740 263043 82.085\n","8750 263347 81.58\n","8760 263651 77.895\n","8770 263954 75.47\n","8780 264255 71.085\n","8790 264560 71.155\n","8800 264858 66.565\n","8810 265162 73.175\n","8820 265465 79.395\n","8830 265741 75.745\n","8840 266041 73.975\n","8850 266345 73.505\n","8860 266651 74.645\n","8870 266947 71.59\n","8880 267252 77.955\n","8890 267557 80.99\n","8900 267861 83.4\n","8910 268164 71.715\n","8920 268465 66.06\n","8930 268768 71.885\n","8940 269069 73.2\n","8950 269373 77.495\n","8960 269674 78.86\n","8970 269979 79.225\n","8980 270280 70.77\n","8990 270582 73.155\n","9000 270886 72.89\n","9010 271187 78.53\n","9020 271490 84.13\n","9030 271791 87.07\n","9040 272093 86.58\n","9050 272394 75.465\n","9060 272696 75.605\n","9070 273000 78.115\n","9080 273303 83.275\n","9090 273604 76.65\n","9100 273906 72.52\n","9110 274207 72.24\n","9120 274508 68.785\n","9130 274812 69.47\n","9140 275114 71.195\n","9150 275415 77.945\n","9160 275718 75.83\n","9170 276020 75.925\n","9180 276320 77.4\n","9190 276623 80.23\n","9200 276926 86.035\n","9210 277226 83.305\n","9220 277526 80.595\n","9230 277830 83.89\n","9240 278130 78.74\n","9250 278431 79.38\n","9260 278731 67.875\n","9270 279033 65.545\n","9280 279334 59.585\n","9290 279636 61.02\n","9300 279940 59.435\n","9310 280238 64.835\n","9320 280539 68.56\n","9330 280841 61.77\n","9340 281143 55.61\n","9350 281445 54.635\n","9360 281745 65.465\n","9370 282046 60.965\n","9380 282348 68.495\n","9390 282649 58.785\n","9400 282954 63.245\n","9410 283257 67.335\n","9420 283560 67.24\n","9430 283862 66.84\n","9440 284164 70.75\n","9450 284466 68.75\n","9460 284768 74.055\n","9470 285070 78.945\n","9480 285370 75.495\n","9490 285672 84.945\n","9500 285975 79.045\n","9510 286277 73.19\n","9520 286581 69.945\n","9530 286885 76.86\n","9540 287188 82.06\n","9550 287489 86.58\n","9560 287791 87.495\n","9570 288092 78.38\n","9580 288396 80.705\n","9590 288700 76.9\n","9600 289002 79.24\n","9610 289305 83.345\n","9620 289608 81.77\n","9630 289909 78.865\n","9640 290212 78.715\n","9650 290517 78.505\n","9660 290818 71.84\n","9670 291120 80.1\n","9680 291423 74.965\n","9690 291727 76.14\n","9700 292029 80.825\n","9710 292331 80.645\n","9720 292632 83.025\n","9730 292918 72.23\n","9740 293221 66.785\n","9750 293522 58.495\n","9760 293825 61.925\n","9770 294127 56.7\n","9780 294429 63.865\n","9790 294727 66.37\n","9800 295027 59.41\n","9810 295329 54.68\n","9820 295608 53.54\n","9830 295911 66.1\n","9840 296214 73.24\n","9850 296491 79.4\n","9860 296795 79.93\n","9870 297099 87.725\n","9880 297403 85.8\n","9890 297707 86.455\n","9900 298011 92.45\n","9910 298313 89.855\n","9920 298609 88.2\n","9930 298911 81.82\n","9940 299214 81.82\n","9950 299516 83.55\n","9960 299820 82.38\n","9970 300122 79.495\n","9980 300423 76.24\n","9990 300725 70.94\n","10000 301024 63.205\n"]}],"source":["for _ in range(max_episodes):\n","  state, info = env.reset()\n","  state = preprocess_state(state)\n","  action_mask = info['action_mask'].reshape((-1,))\n","  episode_reward = 0\n","\n","  for timestep in range(1, max_steps_per_episode):\n","    frame_count += 1\n","\n","    if np.any(action_mask):  # action_mask에 유효한 행동이 있는지 확인\n","      action = get_greedy_epsilon(model, state, action_mask)\n","    else:\n","\n","      break\n","\n","    state_next, reward, done, _, info = env.step((action // 8, action % 8))\n","    state_next = preprocess_state(state_next)\n","    action_mask = info['action_mask'].reshape((-1,))\n","\n","    episode_reward += reward\n","\n","    action_history.append(action)\n","    action_mask_history.append(action_mask)\n","    state_history.append(state)\n","    state_next_history.append(state_next)\n","    rewards_history.append(reward)\n","    done_history.append(done)\n","\n","    state = state_next\n","\n","    if frame_count % update_after_actions == 0 and len(done_history) > batch_size:\n","      update_network()\n","\n","    if frame_count % update_target_network == 0:\n","      model_target.load_state_dict(model.state_dict())\n","\n","    if len(rewards_history) > max_memory_length:\n","      del rewards_history[:1]\n","      del state_history[:1]\n","      del state_next_history[:1]\n","      del action_history[:1]\n","      del action_mask_history[:1]\n","      del done_history[:1]\n","    if done:\n","      break\n","\n","  episode_count += 1\n","  episode_reward_history.append(episode_reward)\n","\n","  if len(episode_reward_history) > 100:\n","    del episode_reward_history[0]\n","\n","  running_reward = np.mean(episode_reward_history)\n","\n","  if episode_count % 10 == 0:\n","    print(episode_count, frame_count, running_reward)"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Current state of the board:\n","    0 1 2 3 4 5 6 7\n","-------------------\n","0 | 1 1 1 1 1 1 1 1\n","1 | 1 1 1 1 2 1 1 1\n","2 | 1 1 1 2 1 2 1 1\n","3 | 1 1 2 2 2 1 1 1\n","4 | 1 1 1 1 1 1 1 2\n","5 | 1 1 1 2 2 1 2 2\n","6 | 1 1 1 1 1 2 2 2\n","7 | 1 1 1 1 1 1 2 2\n","Game over! - Winner 1\n","Gym player: 2, Agent player: 1\n","<class 'str'>\n"]}],"source":["import time, sys\n","from IPython.display import clear_output\n","board, info = env.reset()\n","state = preprocess_state(board)\n","action_mask = info['action_mask'].reshape((-1,))\n","done = False\n","env.render()\n","while not done:\n","  action = get_greedy_action(model, state, action_mask)\n","  print(\"action: ({}, {})\".format(action // 8, action % 8))\n","  sys.stdout.flush()\n","  time.sleep(1.0)\n","  clear_output(wait=False)\n","  board, reward, done, _,info= env.step((action // 8, action % 8))\n","  state = preprocess_state(board)\n","  action_mask = info['action_mask'].reshape((-1,))\n","  env.render()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
